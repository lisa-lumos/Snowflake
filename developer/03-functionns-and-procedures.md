# 3. Functions and Procedures
## Function or Procedure?
With a UDF, 
- Typically calculate and return a value
- Can be called as part of a sql statement
- Must return a value 
- Supported handler languages: Java, JS, Python, Scala, SQL

With a SP, 
- Generally perform administrative operations, by executing SQL statements
- Can perform typical db operations, such as typical queries and DML/DDL
- Optionally return a value
- Supported handler languages: Java, JS, Python, Scala, Snowflake Scripting

Note that every CREATE PROCEDURE statement must include a RETURNS clause that specifies a return type, even if the procedure does not explicitly return anything,in which case, it implicitly returns NULL.

The value returned by a SP, unlike those returned by a function, cannot be used directly in SQL.

Indirect ways to use the return value of a SP:
- Call a SP from inside of another SP
- RESULT_SCAN() after calling the SP
- Store the result set in a temp/perm table in the SP
- Return a VARIANT, if data set is small enough

UDF and SP are called differently: 
```sql
call mySP(argc1); -- call a SP
select myfunc(col1) from table1; -- use a udf
```

A single executable statement can call only one SP. In contrast, a single SQL statement can call multiple functions.

Unlike SPs, UDFs do not have access to an API that can perform database operations.

## Guidelines
### Handler code inline with sql, or on a stage?
Handler code lives in-line with sql:
- Easy to implement/deploy
- Has an upper limit on the source code size
- Change the code via ALTER FUNCTION/PROCEDURE

If the in-line handler source code needs to be compiled (Java/Scala), Snowflake manages compiled output as such:
- If the SQL statement (such as CREATE FUNCTION) uses TARGET_PATH to specify a output location (such as for the JAR file), Snowflake compiles the code once, and keeps the compiled output for future use. This can result in faster execution on repeated calls.
- If the SQL statement does not specify a output location, Snowflake re-compiles the code each time it was called. Snowflake automatically cleans up the file after the SQL statement finishes.

Handler code lives in stage:
- Can use compiled code
- Can use code that is too big to paste into sql statement
- One handler file can contain many handler functions, so many functions/procedures can use them. 
- When code is large/complex, using existing testing/debugging tools are convenient. 

If you delete or rename the handler file, you can no longer call the function/procedure. To update your handler file:
- First, ensure that no calls are being made to the function/procedure that uses the handler.
- Use the PUT command to upload a new handler file. Use the PUT command OVERWRITE=TRUE clause to overwrite the old handler file.

### Security Practices
Handler code executes within a restricted engine. 

Neither your code, nor the code in your library methods, should invoke these prohibited system calls:
- Process control, such as forking a process.
- Access to the file system, on which the code running; while your code can: 
  - read staged files, which are specified in the IMPORTS clause
  - write files, such as log files, to the /tmp dir.
- Network access. But you can call external functions. 

Snowflake prohibits loading libraries that contain native code (as opposed to Java bytecode).

### Secure UDFs and Procedures
Setting it secure prevents users from seeing definition specifics:
- Body (such as between $$)
- List of imports
- Handler name
- Packages list

These info are visible only to the owner. 

For functions and procedures written in Java/Python/Scala, setting secure ensures that they are executed in separate sandboxes, so no resources are shared between them.

Some internal optimizations for UDFs, including pushdown, might allow hidden data to be exposed to users indirectly. Secure UDFs do not use these optimizations. 

When evaluating secure UDFs, the Snowflake query optimizer bypasses the optimizations used for regular UDFs. This might reduce query performance.

If keys generated by a sequence are exposed to users, who do not have access to all of the underlying data, then a user might be able to guess details of the underlying data distribution. You can Use randomized identifiers (such as UUID_STRING), instead of sequence-generated values; or, programmatically obfuscate the identifiers.

To avoid performance characteristics of queries exposing info on the quantity of underlying data, materialize data per user/role, instead of exposing functions on the base data to users.

When using secure UDFs with data sharing, the CURRENT_ACCOUNT() function can be used to authorize users from a specific account to access rows in a base table. Note that CURRENT_ROLE() and CURRENT_USER() functions cannot be used for a share because they return NULLs. 

See if a function/procedure is secure: SHOW FUNCTIONS/PROCEDURES command. 

The internals of a secure function are not exposed in Query Profile - not even for the owner, since non-owners may have access to an owner's Query Profile.

### Pushdown Optimization and Data Visibility
Pushdown optimization: Snowflake makes query processing faster/efficient, by filtering rows early, and apply the most selective filters first. In this way, only needed micro-partitions are fetched by the warehouse. 

However, filters can be reordered by query optimizer, so pushdown can expose data indirectly, which you might not want.

An example showed that a user can deduce information about rows that the user cannot view directly, using the `1/IFF(category = 'MentalHealth', 0, 1) = 1;`, by observing whether the query returns an "divide by zero" error.

### Designing for Snowflake Constraints
During run time, these limitations are enforced:
- Avoid to consume too much memory, either by large values, or by stack depth. 
- Avoid long running algorithms
- Do not use libraries that may introduce security problems, such as writing to files

### Data Type Mappings for functions/SPs
skipped

### Naming Conventions for functions/SPs
Built-in, system-defined functions provided by Snowflake have no namespace, so you can call them from anywhere.

Snowflake supports overloading of procedure and function names, as long as their signatures differ. 

### Uploading Dependencies
When your UDF or SP uses external code/files (such as Python module, Java/Scala JAR, config files, ...), you can upload the dependency to a stage, then referencing it with IMPORTS clause (such as `IMPORTS = ('@mystage/MyCompiledJavaCode.jar')`).

## Packaging Handler Code
Scala build tool (sbt), and Maven. 

## Stored Procedures
From a SP, you can return a single value or tabular data.

You might want to use a SP to automate a task that requires multiple SQL statements and is performed frequently. 

For example, if you want to clean up a database by deleting data older than a specified date for multiple tables. You can put all of those statements in a single SP and pass a parameter that specifies the cut-off date. Then you can call the procedure. As your database changes, you can update the procedure to clean up additional tables; if there are multiple users who use the cleanup command, they can call one procedure, rather than remember every table name and clean up each table individually.

`You can write a handler in the following languages:`
- Java (using the Snowpark API)
- JavaScript
- Python (using the Snowpark API)
- Scala (using the Snowpark API)
- Snowflake Scripting (SQL)

### Usage
SPs are not atomic. You can use SPs with transactions to make a group of statements atomic. 

Best practices:
- If a SP makes temp changes to your session, then that procedure should undo those changes before returning.
- If a SP uses exception handling/branching/etc, you need to clean up whatever you created, regardless of which branches you take during a particular invocation.

For a role to use a SP, they must either be the owner, or have USAGE privilege on the SP.

Although SPs allow nesting/recursion, the current max stack depth of nested calls for user-defined SPs is 5.

You can minimize the risk of SQL injection attacks, by binding parameters, rather than concatenating text.

SPs are usually written to be re-used/shared. Documenting them can make them easier to use/maintain.

### Caller and Owner Rights
A SP runs with either the caller's rights, or the owner's rights. When a SP is created/altered, the owner can specify which right it runs with. `The default is owner's rights.` 

A caller's rights SP runs with caller's privileges: 
- Can read/set/unset the caller's [session parameters/variables]. Its modifications to the session persist after the call completes. 
- Uses caller's warehouse. 
- Uses caller's current db/schema. 
- Caller can see the code. 

An owner's rights SP runs with owner's privileges:
- Cannot view/set/unset [session variables]. 
- Can view some caller's [session parameters], but cannot set/unset them. 
- Uses caller's warehouse. 
- Uses the db/schema that the SP was created in, not caller's settings. 
- Caller cannot see the code. 

The advantage of an owner's rights SP is that, the owner can delegate specific admin tasks, such as cleaning up old data, to another role without granting that role more general privileges, such as privileges to delete all data from a specific table.

To better isolate SP from the rest of the session:
- Avoid using session variables directly - pass them as explicit parameters.
- Clean up any session variables that you set inside the SP; and use rare names, so you don't accidentally clean up a pre-existing session variable).


### Creating


### Calling



## User-Defined Functions
### Privileges
### Creating
### Calling

## Logging and Tracing












