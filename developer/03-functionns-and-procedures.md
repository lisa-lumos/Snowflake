# 3. Functions and Procedures
## Function or Procedure?
With a UDF, 
- Typically calculate and return a value
- Can be called as part of a sql statement
- Must return a value 
- Supported handler languages: Java, JS, Python, Scala, SQL

With a SP, 
- Generally perform administrative operations, by executing SQL statements
- Can perform typical db operations, such as typical queries and DML/DDL
- Optionally return a value
- Supported handler languages: Java, JS, Python, Scala, Snowflake Scripting

Note that every CREATE PROCEDURE statement must include a RETURNS clause that specifies a return type, even if the procedure does not explicitly return anything,in which case, it implicitly returns NULL.

The value returned by a SP, unlike those returned by a function, cannot be used directly in SQL.

Indirect ways to use the return value of a SP:
- Call a SP from inside of another SP
- RESULT_SCAN() after calling the SP
- Store the result set in a temp/perm table in the SP
- Return a VARIANT, if data set is small enough

UDF and SP are called differently: 
```sql
call mySP(argc1); -- call a SP
select myfunc(col1) from table1; -- use a udf
```

A single executable statement can call only one SP. In contrast, a single SQL statement can call multiple functions.

Unlike SPs, UDFs do not have access to an API that can perform database operations.

## Guidelines
### Handler code inline with sql, or on a stage?
Handler code lives in-line with sql:
- Easy to implement/deploy
- Has an upper limit on the source code size
- Change the code via ALTER FUNCTION/PROCEDURE

If the in-line handler source code needs to be compiled (Java/Scala), Snowflake manages compiled output as such:
- If the SQL statement (such as CREATE FUNCTION) uses TARGET_PATH to specify a output location (such as for the JAR file), Snowflake compiles the code once, and keeps the compiled output for future use. This can result in faster execution on repeated calls.
- If the SQL statement does not specify a output location, Snowflake re-compiles the code each time it was called. Snowflake automatically cleans up the file after the SQL statement finishes.

Handler code lives in stage:
- Can use compiled code
- Can use code that is too big to paste into sql statement
- One handler file can contain many handler functions, so many functions/procedures can use them. 
- When code is large/complex, using existing testing/debugging tools are convenient. 

If you delete or rename the handler file, you can no longer call the function/procedure. To update your handler file:
- First, ensure that no calls are being made to the function/procedure that uses the handler.
- Use the PUT command to upload a new handler file. Use the PUT command OVERWRITE=TRUE clause to overwrite the old handler file.

### Security Practices
Handler code executes within a restricted engine. 

Neither your code, nor the code in your library methods, should invoke these prohibited system calls:
- Process control, such as forking a process.
- Access to the file system, on which the code running; while your code can: 
  - read staged files, which are specified in the IMPORTS clause
  - write files, such as log files, to the /tmp dir.
- Network access. But you can call external functions. 

Snowflake prohibits loading libraries that contain native code (as opposed to Java bytecode).

### Secure UDFs and Procedures
Setting it secure prevents users from seeing definition specifics:
- Body (such as between $$)
- List of imports
- Handler name
- Packages list

These info are visible only to the owner. 

For functions and procedures written in Java/Python/Scala, setting secure ensures that they are executed in separate sandboxes, so no resources are shared between them.

Some internal optimizations for UDFs, including pushdown, might allow hidden data to be exposed to users indirectly. Secure UDFs do not use these optimizations. 

When evaluating secure UDFs, the Snowflake query optimizer bypasses the optimizations used for regular UDFs. This might reduce query performance.

If keys generated by a sequence are exposed to users, who do not have access to all of the underlying data, then a user might be able to guess details of the underlying data distribution. You can Use randomized identifiers (such as UUID_STRING), instead of sequence-generated values; or, programmatically obfuscate the identifiers.

To avoid performance characteristics of queries exposing info on the quantity of underlying data, materialize data per user/role, instead of exposing functions on the base data to users.

When using secure UDFs with data sharing, the CURRENT_ACCOUNT() function can be used to authorize users from a specific account to access rows in a base table. Note that CURRENT_ROLE() and CURRENT_USER() functions cannot be used for a share because they return NULLs. 

See if a function/procedure is secure: SHOW FUNCTIONS/PROCEDURES command. 

The internals of a secure function are not exposed in Query Profile - not even for the owner, since non-owners may have access to an owner's Query Profile.

### Pushdown Optimization and Data Visibility
Pushdown optimization: Snowflake makes query processing faster/efficient, by filtering rows early, and apply the most selective filters first. In this way, only needed micro-partitions are fetched by the warehouse. 

However, filters can be reordered by query optimizer, so pushdown can expose data indirectly, which you might not want.

An example showed that a user can deduce information about rows that the user cannot view directly, using the `1/IFF(category = 'MentalHealth', 0, 1) = 1;`, by observing whether the query returns an "divide by zero" error.

### Designing for Snowflake Constraints
During run time, these limitations are enforced:
- Avoid to consume too much memory, either by large values, or by stack depth. 
- Avoid long running algorithms
- Do not use libraries that may introduce security problems, such as writing to files

### Data Type Mappings



















### Naming Conventions


### Uploading Dependencies





## Packaging Handler Code


## Stored Procedures


## User-Defined Functions


## Logging and Tracing
































